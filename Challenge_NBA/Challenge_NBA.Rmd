---
title: "Analyse donnÃ©es NBA challenge"
author: "Geoffrey Pouliquen / KÃ©vin Faou / ThÃ©ophile Gotzorides"
date: "20 janvier 2019"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(readr)
library(dplyr)
library(tidyverse)
library(corrplot)
library(gridExtra)
library(knitr)
library(kableExtra)
library(questionr)
library(pROC)
```


</br>
</br>
<span style="color:red">
PrÃ©sentation des donnÃ©es  
</span>
Les donnÃ©es reprÃ©sentent onze statistiques de match relevÃ©es Ã  chaque seconde jusquâÃ  la mi-temps. De plus, Les statistiques ne sont pas relatives aux performances de chaque Ã©quipe mais reprÃ©sentent lâÃ©cart entre les deux Ã©quipes sur chaque statistique. Par consÃ©quent, les donnÃ©es nÃ©gatives (resp. positives) signifient un avantage pour lâÃ©quipe Ã©voluant Ã  domicile (resp. extÃ©rieure).  
Les statistiques relevÃ©es sont les suivantes :  
- Score : Score du match  
- Offensive Rebound : RÃ©cupÃ©ration de la balle aprÃ¨s un tir manquÃ© de son Ã©quipe  
- Defensive rebound : RÃ©cupÃ©ration de la balle aprÃ¨s un tir manquÃ© de l'Ã©quipe adverse  
- Offensive foul : Faute offensive  
- Defensive foul : Faute dÃ©fensive  
- Assist : DerniÃ¨re passe avant un tir rÃ©ussi  
- Lost ball : Balle perdue  
- Steals : RÃ©cupÃ©ration de la balle  
- Bad pass : Passe interceptÃ©e ou sortie du terrain  
- Block : Tir adverse bloquÃ©  
- Miss : Tir manquÃ©  

Les donnÃ©es contiennent Ã©galement le numÃ©ro d'identification et le vainqueur de chaque match via les variables ID et Match winner. Concernant la variable Match winner, un 0 reprÃ©sente une victoire de l'Ã©quipe jouant Ã  domicile et un 1 une victoire de l'Ã©quipe jouant Ã  l'extÃ©rieure.

Pour faciliter l'analyse des donnÃ©es, chaque match a Ã©tÃ© divisÃ© en quatre "huitiÃ¨mes-de-temps" (HT) de 6 minutes (360 secondes), la moitiÃ© d'un quart-temps. Pour chacune des 11 statistiques relevÃ©es, les donnÃ©es de chaque seconde de ces HT ont Ã©tÃ© rassemblÃ©es en une seule, reprÃ©sentant la moyenne de la statistique sur ce HT. Cela a permis de rÃ©duire le nombre de variables Ã  analyser de 15841 Ã  47.



</br>
</br>
<span style="color:red">
Analyse des variables  
</span>
Echantillon : 12576 appareils matchs    
Variables : 42  

Variable qualitative binaire    
Match winner (0 ou 1)  

Variable quantitative discrÃ¨te
ScoreMT

Variables quantitatives continues  
Score  
Offensive Rebound  
Defensive rebound  
Offensive foul  
Defensive foul  
Assist  
Lost ball  
Steals  
Bad pass  
Block  
Miss  
(On ne considÃ¨re pas ID comme une variable Ã  analyser)  


</br>
<span style="color:blue">
Traitement des variables  
</span>
Les statistiques Defensive foul n'ayant que des valeurs nulles, elles sont retirÃ©es.
Les matchs 1939 et 4058 ont les mÃªmes statistiques aberrantes (l'Ã©quipe Ã  domicile a 97 points d'avance Ã  la mi-temps), ils ne seront donc pas pris en compte dans l'Ã©tude.

```{r, include=FALSE}
training = read_csv(file = "training.csv")
attach(training)
```

On crÃ©e ensuite, Ã  partir de notre Ã©chantillon de 12574 matchs, un Ã©chantillon test en retirant au hasard un tiers des matchs de l'Ã©chantillon train.  
On peut voir sur le graphe ci-dessous que la variable ScoreMT possÃ¨de bien la mÃªme distribution dans les deux Ã©chantillons.  
```{r, include=FALSE}
# CrÃ©ation des Ã©chantillons train et test
library(caret)
train <- createDataPartition(training$ScoreMT,p =0.66,list = FALSE,times = 1)
```

```{r, echo=FALSE}
plot(density(training$ScoreMT[train],bw="SJ"),col="blue", ylab = "DensitÃ©", xlab = "ScoreMT", main = "Distribution de ScoreMT pour les Ã©chantillons train et test")
lines(density(training$ScoreMT[-train],bw="SJ"),col="red")
legend("topright",c("train","test"),col = c("blue","red"), lty = 1)
```

```{r, include=FALSE}
testing = training[-train,]
training = training[train,]
ScoreMT = training[46]
`Match winner` = as.factor(`Match winner`)
```


</br>
<span style="color:blue">
Analyse descriptive multivariÃ©e  
</span>
Afin de dÃ©terminer lâinfluence quâon les diffÃ©rentes variables les unes sur les autres, on dÃ©bute cette Ã©tude par une analyse descriptive multivariÃ©e. On cherche donc les corrÃ©lations entre les diffÃ©rentes variables.  
On commence par Ã©tudier les corrÃ©lations entre les variables dâun mÃªme HT, le dernier.  

```{r, echo=FALSE, warning=FALSE}
corrplot(cor(training[,32:41]))
```

Analysons ces corrÃ©lations :  
- Score et Assist : Le score est logiquement corrÃ©lÃ© aux nombres de passes dÃ©cisives. La corrÃ©lation n'est pas de 1 car il est possible de marquer panier suite Ã  une action solitaire ou grÃ¢ce Ã  un lancer franc.  
- Score et Miss : Moins une Ã©quipe manque de tir, plus elle marque.  
- Miss et Offensive rebound : Plus une Ã©quipe rate de tir, plus elle est susceptible de rÃ©cupÃ©rer la balle suite Ã  un tir ratÃ©.  
- Miss et Defensive rebound : Un tir manquÃ© permet Ã  l'Ã©quipe adverse de rÃ©cupÃ©rer le balle.  
- Steals et Bad pass : Une mauvaise passe entraÃ®ne souvent une interception.  

La corrÃ©lation entre Score et Defensive rebound est plus mystÃ©rieuse. Elle peut cependant sâexpliquer par le fait que rÃ©cupÃ©rer la balle aprÃ¨s un tir manquÃ© de lâÃ©quipe adverse permet de lancer une action ou une contre-attaque. En effet, au basket, la plupart des actions aboutissent Ã  un panier. De plus, la contre-attaque est une phase de jeu au cours de laquelle il est beaucoup plus facile de marquer.  


</br>
En analysant les corrÃ©lations entre les variables de tous les HT, on peut voir lâimpact du temps sur les corrÃ©lations entre les variables.  
```{r, echo=FALSE, warning=FALSE}
corrplot(cor(training[,2:41]))
```

On peut voir sur le graphe ci-dessus que les corrÃ©lations sont identiques, bien que moins fortes, au cours de tous les HT. Lâimpact dâune statistique Ã  un instant t sur sa valeur future est de plus en plus faible Ã  mesure que le match progresse. Cette analyse est confirmÃ©e par le graphe des corrÃ©lations entre les 4 variables Score. Pour prÃ©dire le vainqueur du match, et donc le score final, il semble nÃ©cessaire de sâappuyer sur les donnÃ©es relatives au dernier HT plutÃ´t que sur les donnÃ©es des premiÃ¨res minutes du match.  
On constate Ã©galement que la variable la plus corrÃ©lÃ©e au score dâHT est le score du HT prÃ©cÃ©dent.  On va donc sâintÃ©resser Ã  la variable ScoreMT qui reprÃ©sente le score Ã  la mi-temps, câest-Ã -dire le score le plus proche, sur lâaxe des temps, du score final.

```{r, echo=FALSE}
corrplot(cor(training[c(2,12,22,32)]))
```


</br>
</br>
<span style="color:blue">
Analyse de ScoreMT  
</span>
Afin de mieux Ã©tudier lâimpact du score Ã  la mi-temps sur le rÃ©sultat final du match, on regroupe les valeurs de ScoreMT en diffÃ©rentes classes. Ce regroupement est fait en fonction de la probabilitÃ© de victoire de lâÃ©quipe qui mÃ¨ne Ã  la mi-temps comme le montre le tableau ci-dessus.  
Le tableau Ã  droite donne les chances de victoire de chaque Ã©quipe en fonction du score Ã  la mi-temps. On peut voir que, hormis les matchs oÃ¹ le score est trÃ¨s serrÃ©, ScoreMT semble Ãªtre la variable adÃ©quate pour prÃ©dire le vainqueur du match.

```{r, include=FALSE}
training$ScoreMT = cut(training$ScoreMT,breaks=c(min(training$ScoreMT),-20,-13,-9,-6,-3,2,5,7,11,max(training$ScoreMT)),include.lowest = T)

freq_obs<-table(training$ScoreMT,training$'Match winner')
freq_marg<-addmargins(freq_obs)
freq_cond = freq_marg
for (i in c(1:11))
  freq_cond[i,] = freq_cond[i,]/freq_cond[i,3]
```
```{r, echo=FALSE}
freq_cond[,1:2] %>%
  kable(digit = 3, caption = "Table des probabilitÃ©s") %>%
  kable_styling(full_width = F)
```


On regroupe cette fois ScoreMT en trois classes : lâÃ©quipe Ã  domicile mÃ¨ne, le match est serrÃ© et lâÃ©quipe Ã  lâextÃ©rieure mÃ¨ne. On peut voir alors que miser sur lâÃ©quipe en tÃªte Ã  la mi-temps, si le score nâest pas trop serrÃ©, permet de dÃ©terminer le vainqueur du match avec une probabilitÃ©, particuliÃ¨rement Ã©levÃ©e, de 76,5%.
Les matchs indÃ©cis, particuliÃ¨rement imprÃ©visibles, reprÃ©sentent 20% de lâÃ©chantillon.  

```{r, include=FALSE}
training = cbind(training[1:41],ScoreMT,training[47])
training$ScoreMT =cut(training$ScoreMT,breaks=c(-44,-3,2,39),include.lowest = T)

freq_obs<-table(training$ScoreMT,training$'Match winner')
freq_marg<-addmargins(freq_obs)
freq_cond = freq_marg
for (i in c(1:4))
  freq_cond[i,] = freq_cond[i,]/freq_cond[i,3]
```
```{r, echo=FALSE, results='asis'}
freq_marg %>%
  kable(caption = "Table des effectifs") %>%
  kable_styling(full_width = F)
freq_cond[,1:2] %>%
  kable(digit = 3, caption = "Table des probabilitÃ©s") %>%
  kable_styling(full_width = F)
```

</br>
Si on tient compte des matchs indÃ©cis, alors on peut prÃ©voir le rÃ©sultat du match Ã  seulement 72%.

```{r, include=FALSE}
training = cbind(training[1:41],ScoreMT,training[43])
training$ScoreMT = cut(training$ScoreMT,breaks=c(-44,1,39),include.lowest = T)

freq_obs<-table(training$ScoreMT,training$'Match winner')
freq_marg<-addmargins(freq_obs)
freq_cond = freq_marg
for (i in c(1:3))
  freq_cond[i,] = freq_cond[i,]/freq_cond[i,3]
```
```{r, echo=FALSE, results='asis'}
freq_cond[,1:2] %>%
  kable(digit = 3, caption = "Table des probabilitÃ©s") %>%
  kable_styling(full_width = F)
```








</br>
</br>
</br>
<span style="color:red">
RÃ©gression linÃ©aire sur le modÃ¨le complet  
</span>
 
Ayant contastÃ© lâimportance de lâÃ©cart de points Ã  la mi-temps dans le rÃ©sultat du match, nous allons essayer de prÃ©dire cette valeur Ã  lâaide dâune regression linÃ©aire. Nous le ferons avec deux jeux de donnÃ©es diffÃ©rents, lâun contenant les valeurs du premier quart-temps et lâautre les donnÃ©es aprÃ¨s 18 minutes de jeu. Cela nous permettra de montrer lâÃ©volution de la qualitÃ© de notre prÃ©diction en fonction du temps de jeu Ã©coulÃ©.  
Pour cela, dans les deux cas, on ajuste le modÃ¨le complet par moindres carrÃ©s sur lâÃ©chantillon dâapprentissage puis on compare les valeurs ajustÃ©es aux valeurs prÃ©dites par le modÃ¨le pour les Ã©chantillon dâapprentissage et de test.  

```{r, echo=FALSE}
training = cbind(training[1:41],ScoreMT,training[43])
rm(ScoreMT)
colnames(training) = str_replace(str_replace(names(training)," ","_")," ","_")
colnames(testing) = str_replace(str_replace(names(testing)," ","_")," ","_")

reg_training18 = cbind(training[2:31],training[42])
reg_testing18 = cbind(testing[2:31],testing[46])
reg_training12 = cbind(training[2:21],training[42])
reg_testing12 = cbind(testing[2:21],testing[46])

lm.fit12<-lm(ScoreMT~.,data=reg_training12)
#summary(lm.fit12)
lm.fit18<-lm(ScoreMT~.,data=reg_training18)
#summary(lm.fit18)
```

Pour cela, dans les deux cas, on ajuste le modÃ¨le complet par moindres carrÃ©s sur lâÃ©chantillon dâapprentissage puis on compare les valeurs ajustÃ©es aux valeurs prÃ©dites par le modÃ¨le pour les Ã©chantillon dâapprentissage et de test.

```{r, echo=FALSE}
#calcul des valeurs ajustees
lm.pred.train12<-predict(lm.fit12,reg_training12[,-length(reg_training12)])
lm.pred.train18<-predict(lm.fit18,reg_training18[,-length(reg_training18)])

#Comparaison graphique entre les valeurs ajustees et valeurs predites
par(mfrow=c(1,2))
plot(reg_training12$ScoreMT,lm.pred.train12, xlab = "ScoreMT", ylab = "Valeur prÃ©dite Ã  12 minutes")
abline(0,1,col="red")
plot(reg_training18$ScoreMT,lm.pred.train18, xlab = "ScoreMT", ylab = "Valeur prÃ©dite Ã  18 minutes")
abline(0,1,col="red")
title(main="Graphe des valeur prÃ©dites de ScoreMT pour l'Ã©chantillon train",outer=T, line=-1)
```
</br>
</br>
```{r, echo=FALSE}
#Calcul des valeurs prÃ©dites
lm.pred.test12<-predict(lm.fit12,reg_testing12[-length(reg_testing12)])
lm.pred.test18<-predict(lm.fit18,reg_testing18[-length(reg_testing18)])

#Comparaison graphique valeurs ajustÃ©es/valeurs prÃ©dites
par(mfrow = c(1,2))
plot(reg_testing12$ScoreMT,lm.pred.test12, xlab = "ScoreMT", ylab = "Valeur prÃ©dite Ã  12 minutes")
abline(0,1,col="red")
plot(reg_testing18$ScoreMT,lm.pred.test18, xlab = "ScoreMT", ylab = "Valeur prÃ©dite Ã  18 minutes")
abline(0,1,col="red")
title(main="Graphe des valeur prÃ©dites de ScoreMT pour l'Ã©chantillon test",outer=T, line=-1)
```

```{r, include=FALSE}
lm.ajust.err12<-mean((reg_training12$ScoreMT-lm.pred.train12)^2)
lm.ajust.err12
lm.pred.err12<-mean((reg_testing12$ScoreMT-lm.pred.test12)^2)
lm.pred.err12

lm.ajust.err18<-mean((reg_training18$ScoreMT-lm.pred.train18)^2)
lm.ajust.err18
lm.pred.err18<-mean((reg_testing18$ScoreMT-lm.pred.test18)^2)
lm.pred.err18
```
Erreurs de prÃ©dictions pour les deux premiers HT  
Erreur ajustÃ©e : `r lm.ajust.err12`  
Erreur de prÃ©diction : `r lm.pred.err12`  

Erreurs de prÃ©dictions pour les trois premiers HT  
Erreur ajustÃ©e : `r lm.ajust.err18`  
Erreur de prÃ©diction : `r lm.pred.err18`  

Les erreurs de prÃ©diction sont proches des erreurs dâajustement ce qui nous permet de valider notre rÃ©gression. On est donc capable de prÃ©dire l'Ã©cart de point Ã  la mi-temps de faÃ§on convenable Ã  partir des donnÃ©es des deux ou trois premiers HT.  

</br>
Estimation des valeurs de Match winner  
A partir des valeurs prÃ©dites de ScoreMT pour l'Ã©chantillon test, on estime le vainqueur de chaque match en utilisant la rÃ¨gle Ã©tablie dans la premiÃ¨re partie. Si l'Ã©quipe Ã  l'extÃ©rieure mÃ¨ne de plus d'un point (ScoreMT > 1) alors on suppose qu'elle va remporter le match. Sinon, on suppose que c'est l'Ã©quipe Ã  domicile qui va l'emporter. 
On estime alors le nombre de bonnes prÃ©dictions en comparant ces valeurs aux valeurs de Match winner de notre Ã©chantillon test.  

```{r, include=FALSE}
test = c()
predict_table = c()
for(i in c(1:length(lm.pred.test12)))
  if(lm.pred.test12[i] <= 1) {
    test[i] = 0
  } else {
    test[i] = 1
  }
predict = test == testing$Match_winner
predict_table[1] = length(predict[predict == TRUE])/length(predict)


for(i in c(1:length(lm.pred.test18)))
  if(lm.pred.test18[i] <= 1) {
    test[i] = 0
  } else {
    test[i] = 1
  }
predict = test == testing$Match_winner
predict_table[2] = length(predict[predict == TRUE])/length(predict)
```

```{r, echo=FALSE}
predict_table_0 = matrix(predict_table)
colnames(predict_table_0) = c("RÃ©gression")
rownames(predict_table_0) = c("12 min","18 min")
predict_table_0 %>%
  kable(digit = 3, caption = "Proportion de bonnes prÃ©dictions") %>%
  kable_styling(full_width = F)
rm(predict_table_0)
```

</br>
SignificativitÃ© des variables
Dans le but d'amÃ©liorer la prÃ©diction, on teste la significativitÃ© des variables du modÃ¨le de rÃ©gression.  

RÃ©gression sur les 2 premiers HT  
```{r, echo=FALSE}
summary(lm.fit12)
```

RÃ©gression sur les 3 premiers HT  
```{r, echo=FALSE}
summary(lm.fit18)
```

On constate rapidement que la plupart des variables ne sont pas significatives (p-valeur > 0,05). On va donc essayer de simuler ScoreMT avec un modÃ¨le sÃ©lectionnant seulement un nombre rÃ©duit de variables pour voir si la prÃ©diction de Match winner sera meilleure.




</br>
</br>
<span style="color:blue">
SÃ©lection de modÃ¨les hybride basÃ© sur le Cp de Mallows  
</span>
On utilise maintenant un autre modÃ¨le pour simuler ScoreMT, le modÃ¨le hybride basÃ© sur le Cp de Mallows.
```{r, include=FALSE}
library(leaps)
regfit.hyb12<-regsubsets(ScoreMT~.,data=reg_training12,nvmax=20,method="seqrep")
regfit.hyb18<-regsubsets(ScoreMT~.,data=reg_training18,nvmax=20,method="seqrep")
```
```{r, echo=FALSE}
par(mfrow=c(1,2))
plot(regfit.hyb12,scale="Cp")
plot(regfit.hyb18,scale="Cp")
title(main="Graphe Cp de Mallows",outer=T, line=-3)
```
</br>
Les graphes ci-dessus montrent les variables Ã  sÃ©lectionner que l'on affiche ci-dessous.
```{r, echo = FALSE, include=FALSE}
#Dimension du modele choisi par Cp
regfit.hyb.summary12<-summary(regfit.hyb12)
bestCp12<-which.min(regfit.hyb.summary12$cp);bestCp12

indCP12<-which(regfit.hyb.summary12$which[bestCp12,]==TRUE)[-1]-1
modCP12<-names(reg_training12)[indCP12]
```
Variables rÃ©cupÃ©rÃ©es pour la simulation Ã  partir des deux premiers HT :  
Nombre de variables conservÃ©es : `r bestCp12`  
`r modCP12`  

```{r, echo = FALSE, include=FALSE}
#Dimension du modele choisi par Cp
regfit.hyb.summary18<-summary(regfit.hyb18)
bestCp18<-which.min(regfit.hyb.summary18$cp);bestCp18

indCP18<-which(regfit.hyb.summary18$which[bestCp18,]==TRUE)[-1]-1
modCP18<-names(reg_training18)[indCP18]
```

Variables rÃ©cupÃ©rÃ©es pour la simulation Ã  partir des trois premiers HT :  
Nombre de variables conservÃ©es : `r bestCp18`  
`r modCP18`  

```{r, include = FALSE}
#Ecriture du modÃ¨le sÃ©lectionnÃ© par Cp
fmlaCP12 <- as.formula(paste("ScoreMT ~ ", paste(modCP12, collapse= "+")))

fmlaCP18 <- as.formula(paste("ScoreMT ~ ", paste(modCP18, collapse= "+")))
```

```{r, echo=FALSE, include=FALSE}
lm.fit.CP12<-lm(fmlaCP12,data=reg_training12) 
summary(lm.fit.CP12)$coef
lm.fit.CP18<-lm(fmlaCP18,data=reg_training18) 
summary(lm.fit.CP18)$coef

#On prend l'ensemble des donnees test
CP.pred.test12<-predict(lm.fit.CP12,reg_testing12)
summary(CP.pred.test12)
CP.pred.test18<-predict(lm.fit.CP18,reg_testing18)
summary(CP.pred.test18)
```

```{r, include=FALSE}
CP.pred.err12<-mean((reg_testing12$ScoreMT-CP.pred.test12)^2)
CP.pred.err12
lm.pred.err12

CP.pred.err18<-mean((reg_testing18$ScoreMT-CP.pred.test18)^2)
CP.pred.err18
lm.pred.err18
```
</br>
Le modÃ¨le sÃ©lectionnÃ© par le Cp de Mallows est validÃ© par le calcul des erreurs de prÃ©diction sur lâÃ©chantillon test.  
Erreurs de prÃ©dictions pour les deux premiers HT  
Erreur de prÃ©diction CP : `r CP.pred.err12`  
Erreur de prÃ©diction rÃ©gression : `r lm.pred.err12`  

Erreurs de prÃ©dictions pour les trois premiers HT  
Erreur de prÃ©diction : `r CP.pred.err18`  
Erreur de prÃ©diction rÃ©gression : `r lm.pred.err18`  

</br>
Comparaison entre le modÃ¨le de rÃ©gression et le modÃ¨le hybride  
En estimant les valeurs de Match winner Ã  partir des valeurs de ScoreMT prÃ©dites par le modÃ¨le hybride, on obtient des rÃ©sultats similaires au modÃ¨le de rÃ©gression linÃ©aire classique.

```{r, include=FALSE}
for(i in c(1:length(CP.pred.test12)))
  if(CP.pred.test12[i] <= 1) {
    test[i] = 0
  } else {
    test[i] = 1
  }
predict = test == testing$Match_winner
predict_table[3] = length(predict[predict == TRUE])/length(predict)

for(i in c(1:length(CP.pred.test18)))
  if(CP.pred.test18[i] <= 1) {
    test[i] = 0
  } else {
    test[i] = 1
  }
predict = test == testing$Match_winner
predict_table[4] = length(predict[predict == TRUE])/length(predict)
```

```{r, echo=FALSE}
predict_table = matrix(predict_table, ncol = 2, nrow = 2)
colnames(predict_table) = c("RÃ©gression","Mallows")
rownames(predict_table) = c("12 min","18 min")
predict_table %>%
  kable(digit = 3, caption = "Proportion de bonnes prÃ©dictions") %>%
  kable_styling(full_width = F)
```




</br>
</br>
</br>
<span style="color:red">
\LARGE RÃ©gression logistique
</span>

Dans les deux parties prÃ©cÃ©dentes, nous avons vu quâil Ã©tait possible de prÃ©voir le rÃ©sultat dâun match Ã  diffÃ©rents niveaux de probabilitÃ© avec une rÃ¨gle de decision simple basÃ© sur le score Ã  la mi-temps (reel ou simulÃ©) . Notre taux de rÃ©ussite est actuellement dâenviron 72%.
On cherche dÃ©sormais Ã  savoir sâil est possible dâobtenir une meilleur prÃ©diction de Match winner Ã  lâaide dâune nouvelle mÃ©thode, la rÃ©gression logistique.  

Nous allons dans cette partie effectuer des rÃ©gressions logistiques afin de trouver le meilleur modÃ¨le capable dâexpliquer le gagnant du match (variable Match winner) en fonction des covariables des 2 premiers quart-temps.  
Nous regarderons tout dâabord le modÃ¨le avec toutes les covariables afin de tester si des variables sont pertinentes puis nous chercherons le meilleur modÃ¨le au sens du critÃ¨re AIC en sÃ©lectionnant les variables. Enfin nous terminerons avec de la prÃ©diction sur la variable Match winner.


### A/ Etude du modÃ¨le complet

On mÃ¨ne une rÃ©gression logistique (famille binomiale) car la variable rÃ©ponse prend des valeurs binaires (0 et 1).
On s'interesse ici au modÃ¨le composÃ© de **toutes les variables explicatives** ou **modÃ¨le complet**. 

```{r, echo=FALSE, results=FALSE}
reg<-glm(formula = Match_winner~Score_6+Score_12+Score_18+Score_24
                                  + Offensive_rebound_6+ Offensive_rebound_12+Offensive_rebound_18+Offensive_rebound_24
                                  + Defensive_rebound_6+ Defensive_rebound_12+Defensive_rebound_18+Defensive_rebound_24
                                  + Offensive_foul_6 + Offensive_foul_12 + Offensive_foul_18+ Offensive_foul_24
                                  + Assist_6+ Assist_12+Assist_18+Assist_24
                                  + Lost_ball_6+ Lost_ball_12+ Lost_ball_18+ Lost_ball_24
                                  + Steals_6+ Steals_12+ Steals_18+ Steals_24
                                  + Bad_pass_6+ Bad_pass_12+ Bad_pass_18+ Bad_pass_24
                                  + Block_6+ Block_12+ Block_18 + Block_24
                                  + Miss_6+ Miss_12+ Miss_18+ Miss_24,
                                  family = binomial, data=training)

#summary(reg)
D0<-reg$null.deviance
D1<-reg$deviance
ecart<-round(D0-D1,2)

chi<-round(qchisq(.95,49),2)
```
$D_0-D_1 =$ `r ecart`

$q_{1-\alpha}(\chi^2_{49}) =$ `r chi`

On regarde le test suivant :

$H_0 :$ **Aucune variable n'explique la rÃ©ponse** $vs$ $H_1 :$ **Il existe au moins une variable explicative pertinente.**


Ici nous avons ** $D_0-D_1 > q_{1-\alpha}(\chi^2_{49})$ ** donc on **rejette $H_0$ : Il existe au moins une variable qui permet d'avoir un modÃ¨le qui explique mieux Match_winner que le modÃ¨le nul.**


#### PrÃ©diction Ã  l'aide du modÃ¨le complet 

Comme le modÃ¨le complet est meilleur que le modÃ¨le avec seulement l'intercept, on effectue une prÃ©diction du gagnant du match sur l'Ã©chantillon de test.

Voici la **table de confusion** :

```{r, echo=FALSE ,results="hold"}
probs<-predict.glm(reg,testing,type="response")
pred<-rep(0,dim(testing)[1])
pred[probs>.5]<-1  


confus0.5<-table(testing$Match_winner,pred)

taille_test<-dim(testing)[1]
bonne_pred<-confus0.5[1,1]+confus0.5[2,2]
mauvaise_pred<-confus0.5[1,2]+confus0.5[2,1]
pourcentage<-round(100*bonne_pred/taille_test,1)
par(mfrow=c(2,2))
confus0.5 %>%
  kable() %>%
  kable_styling(full_width = F)
```

On obtient **`r bonne_pred` sur `r taille_test` de bonnes prÃ©dictions** contre **`r  mauvaise_pred` mauvaises**, soit une **prÃ©diction juste dans `r pourcentage` % des cas**.

```{r,echo=FALSE}
plot(as.integer(as.factor(pred[1:100]))-1,col="blue",pch=2,type="p",ylab="Gagnant du match",xlab="Individus")+ points(as.integer(as.factor(testing$Match_winner[1:100]))-1,col="red",pch=2,type="p")
title(main=" PrÃ©vision du gagnant du match (bleu) et vrais rÃ©sultats (rouge)")
```

On constate qu'assez souvent les prÃ©dictions coÃ¯ncident avec le vrai rÃ©sultat. Nous avons considÃ©rer les 100 premiers individus pour avoir un plot lisible. 

On s'interesse maintenant Ã  la **courbe ROC** : 

```{r,echo=FALSE}
rocobj <- roc(as.numeric(testing$Match_winner),probs)
plot(rocobj, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),max.auc.polygon=TRUE, auc.polygon.col="blue",
     print.thres=TRUE, main="Courbe ROC du modÃ¨le complet de prÃ©diction" )
AUC<-rocobj$auc
```

On retrouve la qualitÃ© de la prÃ©diction, en effet plus l'aire sous la courbe (AUC) est **proche de 1**, meilleure est la prÃ©diction. Ici nous avons une **AUC = `r AUC`** ce qui est assez satisfaisant.

Le **seuil optimal** (probabilitÃ© avec laquelle on attribut la valeur 1 au vecteur prÃ©disant le gagnant du match) se lit **sur la courbe** et donne le meilleur seuil pour lequel la prÃ©diction est la plus fiable.


#### SÃ©lection de variables et ajustement d'un modÃ¨le d'aprÃ¨s le critÃ¨re AIC

On utilise la fonction **stepAIC** avec une **recherche mixte** (mÃ©lange de mÃ©thode forward et backward) afin de trouver le meilleur modÃ¨le au sens du **critÃ¨re AIC**, puis on prÃ©dit de la mÃªme maniÃ¨re le vainqueur du match. 

```{r, echo=FALSE, message=FALSE , include=FALSE}
library(MASS)
reg_select<-stepAIC(reg, direction = "both")

select_prob<-predict.glm(reg_select,testing,type="response")
select_pred<-rep(0,dim(testing)[1])
select_pred[select_prob>.5]<-1 

table_step<-table(select_pred,testing$Match_winner)
bonne_pred_step<-table_step[1,1]+table_step[2,2]
mauvaise_pred_step<-table_step[1,2]+table_step[2,1]
pourcentage_step<-round(100*bonne_pred_step/taille_test,1)
```
Voici les variables retenues pour expliquer le modÃ¨le obtenu par minimisation du critÃ¨re AIC:

`r names(reg_select$model)`


On obtient **`r bonne_pred`** sur **`r taille_test`** de bonnes prÃ©dictions contre **`r  mauvaise_pred`** mauvaises, soit une prÃ©diction juste dans **`r pourcentage` % ** des cas. On retrouve un **rÃ©sultat trÃ¨s similaire** qu'avec la prÃ©diction prÃ©cÃ©dente sauf qu'ici nous avons seulement **11 variables explicatives** contre **44** dans le modÃ¨le complet et nous obtenons la mÃªme prÃ©diction Ã  trÃ¨s peu de choses prÃ¨s. Donc dans le cadre de la prÃ©diction nous pouvons affimer que **75% des variables** explicatives n'apportent pas (ou trÃ¨s peu) d'information supplÃ©mentaire.

On retrouve Ã  peu de chose prÃ¨s la mÃªme courbe ROC logiquement:


```{r, echo=FALSE, fig.height=4 , fig.width=9}
courberoc<-roc(testing$Match_winner,select_prob)
plot(courberoc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),max.auc.polygon=TRUE, auc.polygon.col="pink",
     print.thres=TRUE, main="Courbe ROC du modÃ¨le hybride (critÃ¨re AIC) de prÃ©diction")

```